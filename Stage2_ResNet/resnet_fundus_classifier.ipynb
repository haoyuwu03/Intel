{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet_fundus_classifier.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx-3jU5icB4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Tensorflow Version, Google Colab Only\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSBthz_Hcqv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2004d944-ee21-46c4-a130-030ce4ba7c44"
      },
      "source": [
        "#Mount the Notebook to Drive to Access Files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mngTOXjpfd5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Imports libraries needed\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2 as cv2\n",
        "import os as os\n",
        "import h5py as h5py\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tqdm import tqdm #gives the status of a loop (important if we have large amounts of data and need to see the progress)\n",
        "\n",
        "#Tensorflow Imports\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator #used for data augmentation\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, ZeroPadding2D,\\\n",
        "     Flatten, BatchNormalization, AveragePooling2D, Dense, Activation, Add \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTmTPxCmF9qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loads the images from image preproccessing\n",
        "testing_data = np.load('/content/gdrive/My Drive/Colab Notebooks/compressed_image_arrays/testing_array.npy', allow_pickle=True)\n",
        "training_data = np.load('/content/gdrive/My Drive/Colab Notebooks/compressed_image_arrays/augmented_training_array.npy', allow_pickle=True)\n",
        "validation_data = np.load('/content/gdrive/My Drive/Colab Notebooks/compressed_image_arrays/augmented_validation_array.npy', allow_pickle=True)\n",
        "\n",
        "testing_labels = np.load('/content/gdrive/My Drive/Colab Notebooks/compressed_image_arrays/testing_labels.npy', allow_pickle=True)\n",
        "training_labels = np.load('/content/gdrive/My Drive/Colab Notebooks/compressed_image_arrays/augmented_training_labels.npy', allow_pickle=True)\n",
        "validation_labels = np.load('/content/gdrive/My Drive/Colab Notebooks/compressed_image_arrays/augmented_validation_labels.npy', allow_pickle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjRLPb6FDDM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one hot encode the labels so that their dimensions fit the output\n",
        "def one_hot_encode(labels):\n",
        "  x = 0\n",
        "  for y in labels:\n",
        "    if y =='cataract':\n",
        "      labels[x] = 0\n",
        "    if y == 'hypertensive_retinopathy':\n",
        "      labels[x] = 1\n",
        "    if y == 'glaucoma':\n",
        "      labels[x] = 2\n",
        "    if y == 'diabetic_retinopathy_1':\n",
        "      labels[x] = 3\n",
        "    if y == 'diabetic_retinopathy_2':\n",
        "      labels[x] = 4\n",
        "    if y == 'diabetic_retinopathy_3':\n",
        "      labels[x] = 5\n",
        "    if y == 'diabetic_retinopathy_4':\n",
        "      labels[x] = 6\n",
        "    if y == 'normal':\n",
        "      labels[x] = 7\n",
        "    x = x+1\n",
        "  new_labels = to_categorical(labels)\n",
        "  return new_labels\n",
        "\n",
        "\n",
        "testing_labels = one_hot_encode(testing_labels)\n",
        "training_labels = one_hot_encode(training_labels)\n",
        "validation_labels = one_hot_encode(validation_labels)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTKHZBoOHABV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create ImageDataGenerator for real-time augmentation\n",
        "#We only augment the training data because we train with that data\n",
        "train_data_gen = ImageDataGenerator(zoom_range=0.2, \n",
        "                                   width_shift_range=0.5, \n",
        "                                   height_shift_range = 0.3, \n",
        "                                   rotation_range=30)\n",
        "                                   #horizontal_flip=True,\n",
        "                                   #vertical_flip=True,\n",
        "\n",
        "valid_data_gen = ImageDataGenerator(zoom_range=0.2, \n",
        "                                   width_shift_range=0.2, \n",
        "                                   height_shift_range = 0.2, \n",
        "                                   rotation_range=30)\n",
        "\n",
        "training_data = train_data_gen.flow(training_data, training_labels, batch_size = 32)\n",
        "validation_data = valid_data_gen.flow(validation_data, validation_labels, batch_size = 32)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivVerBVbKDWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_identity(x, filters): \n",
        "  ''' resnet block where dimension doesnot change.\n",
        "  The skip connection is just simple identity conncection\n",
        "  we will have 3 blocks and then input will be added\n",
        "  '''\n",
        "  x_skip = x # this will be used for addition with the residual block \n",
        "  f1, f2 = filters\n",
        "\n",
        "  #first block \n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #second block # bottleneck (but size kept same with padding)\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  # third block activation used after adding the input\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  # x = Activation(activations.relu)(x)\n",
        "\n",
        "  # add the input \n",
        "  x = Add()([x, x_skip])\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def res_conv(x, s, filters):\n",
        "  '''\n",
        "  here the input size changes, when it goes via conv blocks\n",
        "  so the skip connection uses a projection (conv layer) matrix\n",
        "  ''' \n",
        "  x_skip = x\n",
        "  f1, f2 = filters\n",
        "\n",
        "  # first block\n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
        "  # when s = 2 then it is like downsizing the feature map\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  # second block\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #third block\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # shortcut \n",
        "  x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=l2(0.001))(x_skip)\n",
        "  x_skip = BatchNormalization()(x_skip)\n",
        "\n",
        "  # add \n",
        "  x = Add()([x, x_skip])\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def resnet50():\n",
        "\n",
        "  input_im = Input(shape=(224,224,3)) # cifar 10 images size\n",
        "  x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
        "\n",
        "  # 1st stage\n",
        "  # here we perform maxpooling, see the figure above\n",
        "\n",
        "  x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "  #2nd stage \n",
        "  # frm here on only conv block and identity block, no pooling\n",
        "\n",
        "  x = res_conv(x, s=1, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "##152\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "\n",
        "  # 3rd stage\n",
        "\n",
        "  x = res_conv(x, s=2, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "##152\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "\n",
        "  # 4th stage\n",
        "\n",
        "  x = res_conv(x, s=2, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "##152\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "\n",
        "  # 5th stage\n",
        "\n",
        "  x = res_conv(x, s=2, filters=(512, 2048))\n",
        "  x = res_identity(x, filters=(512, 2048))\n",
        "  x = res_identity(x, filters=(512, 2048))\n",
        "#152\n",
        "  x = res_identity(x, filters=(512, 2048))\n",
        "  x = res_identity(x, filters=(512, 2048))\n",
        "  x = res_identity(x, filters=(512, 2048))\n",
        "\n",
        "\n",
        "  # ends with average pooling and dense connection\n",
        "\n",
        "  x = AveragePooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(8, activation='softmax', kernel_initializer='he_normal')(x) #multi-class\n",
        "\n",
        "  # define the model \n",
        "\n",
        "  model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
        "\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBGuPxY4KrEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combines the whole model\n",
        "resnet50_model = resnet50()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4e0KqDkKtbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prints out a whole summary of the model\n",
        "#resnet50_model.summary()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICqxwjoOLHif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compiles the resnet model\n",
        "resnet50_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-3), \n",
        "                       metrics=['acc'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99xGOuedLctZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "be8ece2a-501e-4679-cc70-489b5c7ae922"
      },
      "source": [
        "#build the callbacks\n",
        "\n",
        "#checkpoint callback\n",
        "checkpoint_path = \"/content/gdrive/My Drive/Colab Notebooks/checkpoints_resnet_fundus/training_batch_7_21_2020/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "print(checkpoint_dir)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    period=5)\n",
        "\n",
        "resnet50_model.save_weights(checkpoint_path.format(epoch=0))\n",
        "\n",
        "#learning rate decay callback\n",
        "def lrdecay(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    return lr\n",
        "\n",
        "lrdecay = tf.keras.callbacks.LearningRateScheduler(lrdecay) # learning rate decay  \n",
        "\n",
        "def earlystop(mode):\n",
        "  if mode=='acc':\n",
        "    estop = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=15, mode='max')\n",
        "  elif mode=='loss':\n",
        "    estop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, mode='min')\n",
        "  return estop\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/checkpoints_resnet_fundus/training_batch_7_21_2020\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7jZxX5XMJ0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpZ-_RAS0XzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "081a40c9-10ff-4bf0-ec75-b13d14d2ce8f"
      },
      "source": [
        "resnet_train = resnet50_model.fit_generator(training_data, \n",
        "                                            epochs=250, \n",
        "                                            steps_per_epoch= 2485 / batch_size, \n",
        "                                            validation_steps= 3332 / batch_size, \n",
        "                                            validation_data = validation_data, \n",
        "                                            callbacks=[lrdecay],)\n",
        "                                            #cp_callback, \n",
        "\n",
        "#okay, so the error on the bottom has something to do with this line:  x = Dense(8, activation='softmax', kernel_initializer='he_normal')(x) #multi-class\n",
        "#the \"8\" parameter is correct because there are (none, 8) outputs, so the input must be (none, 1)\n",
        "#how should i fix this?\n",
        "#should I one hot encode the training, validation and testing labels to so that it will be size 8?\n",
        "#YUP one hot encoding fix it"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-0e5ca027efdd>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/250\n",
            "20/19 [==============================] - 20s 1s/step - loss: 53.8792 - acc: 0.3578 - val_loss: 38.1822 - val_acc: 0.5324 - lr: 0.0010\n",
            "Epoch 2/250\n",
            "20/19 [==============================] - 17s 828ms/step - loss: 41.2403 - acc: 0.4797 - val_loss: 37.6479 - val_acc: 0.5220 - lr: 0.0010\n",
            "Epoch 3/250\n",
            "20/19 [==============================] - 17s 838ms/step - loss: 40.3198 - acc: 0.3922 - val_loss: 36.9133 - val_acc: 0.5000 - lr: 0.0010\n",
            "Epoch 4/250\n",
            "20/19 [==============================] - 17s 830ms/step - loss: 39.4957 - acc: 0.4234 - val_loss: 36.2046 - val_acc: 0.0880 - lr: 0.0010\n",
            "Epoch 5/250\n",
            "20/19 [==============================] - 17s 830ms/step - loss: 37.2713 - acc: 0.4344 - val_loss: 35.6229 - val_acc: 0.0741 - lr: 0.0010\n",
            "Epoch 6/250\n",
            "20/19 [==============================] - 17s 841ms/step - loss: 35.9096 - acc: 0.4375 - val_loss: 34.6268 - val_acc: 0.0775 - lr: 0.0010\n",
            "Epoch 7/250\n",
            "20/19 [==============================] - 17s 831ms/step - loss: 34.7782 - acc: 0.5047 - val_loss: 33.1923 - val_acc: 0.4850 - lr: 0.0010\n",
            "Epoch 8/250\n",
            "20/19 [==============================] - 17s 835ms/step - loss: 33.0382 - acc: 0.5562 - val_loss: 32.2688 - val_acc: 0.4271 - lr: 0.0010\n",
            "Epoch 9/250\n",
            "20/19 [==============================] - 17s 828ms/step - loss: 31.8011 - acc: 0.5797 - val_loss: 31.2045 - val_acc: 0.4340 - lr: 0.0010\n",
            "Epoch 10/250\n",
            "20/19 [==============================] - 17s 829ms/step - loss: 30.7989 - acc: 0.5141 - val_loss: 32.0111 - val_acc: 0.0949 - lr: 0.0010\n",
            "Epoch 11/250\n",
            "20/19 [==============================] - 17s 845ms/step - loss: 29.8217 - acc: 0.6062 - val_loss: 30.3923 - val_acc: 0.0845 - lr: 0.0010\n",
            "Epoch 12/250\n",
            "20/19 [==============================] - 17s 828ms/step - loss: 28.7998 - acc: 0.5891 - val_loss: 29.5565 - val_acc: 0.2465 - lr: 0.0010\n",
            "Epoch 13/250\n",
            "20/19 [==============================] - 17s 831ms/step - loss: 28.1729 - acc: 0.5969 - val_loss: 28.5336 - val_acc: 0.0914 - lr: 0.0010\n",
            "Epoch 14/250\n",
            "20/19 [==============================] - 17s 834ms/step - loss: 27.0175 - acc: 0.5969 - val_loss: 27.4962 - val_acc: 0.2465 - lr: 0.0010\n",
            "Epoch 15/250\n",
            "20/19 [==============================] - 17s 838ms/step - loss: 26.0009 - acc: 0.6234 - val_loss: 26.0513 - val_acc: 0.4977 - lr: 0.0010\n",
            "Epoch 16/250\n",
            "20/19 [==============================] - 17s 849ms/step - loss: 25.5036 - acc: 0.5813 - val_loss: 25.3078 - val_acc: 0.3229 - lr: 0.0010\n",
            "Epoch 17/250\n",
            "20/19 [==============================] - 17s 833ms/step - loss: 24.5272 - acc: 0.6000 - val_loss: 24.9946 - val_acc: 0.2118 - lr: 0.0010\n",
            "Epoch 18/250\n",
            "20/19 [==============================] - 17s 836ms/step - loss: 23.8271 - acc: 0.6281 - val_loss: 24.5559 - val_acc: 0.2303 - lr: 0.0010\n",
            "Epoch 19/250\n",
            "20/19 [==============================] - 17s 848ms/step - loss: 22.9645 - acc: 0.6442 - val_loss: 23.0256 - val_acc: 0.3738 - lr: 0.0010\n",
            "Epoch 20/250\n",
            "20/19 [==============================] - 17s 842ms/step - loss: 22.2674 - acc: 0.5938 - val_loss: 22.9014 - val_acc: 0.2245 - lr: 0.0010\n",
            "Epoch 21/250\n",
            "20/19 [==============================] - 17s 834ms/step - loss: 21.5549 - acc: 0.6703 - val_loss: 21.9254 - val_acc: 0.2708 - lr: 0.0010\n",
            "Epoch 22/250\n",
            "20/19 [==============================] - 17s 846ms/step - loss: 20.9903 - acc: 0.6703 - val_loss: 21.8349 - val_acc: 0.2431 - lr: 0.0010\n",
            "Epoch 23/250\n",
            "20/19 [==============================] - 17s 851ms/step - loss: 20.4025 - acc: 0.6562 - val_loss: 21.0075 - val_acc: 0.2650 - lr: 0.0010\n",
            "Epoch 24/250\n",
            "20/19 [==============================] - 17s 847ms/step - loss: 19.8123 - acc: 0.7016 - val_loss: 20.1099 - val_acc: 0.3530 - lr: 0.0010\n",
            "Epoch 25/250\n",
            "20/19 [==============================] - 17s 839ms/step - loss: 19.4416 - acc: 0.6766 - val_loss: 19.6759 - val_acc: 0.2963 - lr: 0.0010\n",
            "Epoch 26/250\n",
            "20/19 [==============================] - 17s 839ms/step - loss: 18.9467 - acc: 0.6484 - val_loss: 18.9737 - val_acc: 0.5903 - lr: 0.0010\n",
            "Epoch 27/250\n",
            "20/19 [==============================] - 17s 839ms/step - loss: 18.5165 - acc: 0.6219 - val_loss: 18.8500 - val_acc: 0.2824 - lr: 0.0010\n",
            "Epoch 28/250\n",
            "20/19 [==============================] - 17s 842ms/step - loss: 17.9515 - acc: 0.6609 - val_loss: 18.4527 - val_acc: 0.2940 - lr: 0.0010\n",
            "Epoch 29/250\n",
            "20/19 [==============================] - 17s 845ms/step - loss: 17.6266 - acc: 0.6234 - val_loss: 18.2157 - val_acc: 0.2488 - lr: 0.0010\n",
            "Epoch 30/250\n",
            "20/19 [==============================] - 17s 841ms/step - loss: 17.3481 - acc: 0.6219 - val_loss: 17.3872 - val_acc: 0.3333 - lr: 0.0010\n",
            "Epoch 31/250\n",
            "20/19 [==============================] - 17s 844ms/step - loss: 16.7167 - acc: 0.6656 - val_loss: 17.2650 - val_acc: 0.2095 - lr: 0.0010\n",
            "Epoch 32/250\n",
            "20/19 [==============================] - 17s 832ms/step - loss: 16.3966 - acc: 0.6234 - val_loss: 17.0826 - val_acc: 0.2847 - lr: 0.0010\n",
            "Epoch 33/250\n",
            "20/19 [==============================] - 17s 853ms/step - loss: 16.0032 - acc: 0.6594 - val_loss: 16.2514 - val_acc: 0.4525 - lr: 0.0010\n",
            "Epoch 34/250\n",
            "20/19 [==============================] - 17s 842ms/step - loss: 15.8000 - acc: 0.6453 - val_loss: 16.5414 - val_acc: 0.2627 - lr: 0.0010\n",
            "Epoch 35/250\n",
            "20/19 [==============================] - 17s 850ms/step - loss: 15.5993 - acc: 0.6187 - val_loss: 27.8470 - val_acc: 0.3808 - lr: 0.0010\n",
            "Epoch 36/250\n",
            "20/19 [==============================] - 17s 842ms/step - loss: 15.2656 - acc: 0.6375 - val_loss: 16.6959 - val_acc: 0.6516 - lr: 0.0010\n",
            "Epoch 37/250\n",
            "20/19 [==============================] - 18s 919ms/step - loss: 15.0290 - acc: 0.6297 - val_loss: 14.9759 - val_acc: 0.5961 - lr: 0.0010\n",
            "Epoch 38/250\n",
            "20/19 [==============================] - 19s 941ms/step - loss: 14.6915 - acc: 0.6547 - val_loss: 15.3263 - val_acc: 0.3067 - lr: 0.0010\n",
            "Epoch 39/250\n",
            "20/19 [==============================] - 19s 966ms/step - loss: 14.6662 - acc: 0.6359 - val_loss: 14.2618 - val_acc: 0.6481 - lr: 0.0010\n",
            "Epoch 40/250\n",
            "20/19 [==============================] - 20s 983ms/step - loss: 14.1635 - acc: 0.6328 - val_loss: 14.2178 - val_acc: 0.6377 - lr: 0.0010\n",
            "Epoch 41/250\n",
            "20/19 [==============================] - 17s 868ms/step - loss: 13.9275 - acc: 0.6703 - val_loss: 14.5089 - val_acc: 0.3021 - lr: 0.0010\n",
            "Epoch 42/250\n",
            "20/19 [==============================] - 19s 968ms/step - loss: 13.5851 - acc: 0.6594 - val_loss: 14.1695 - val_acc: 0.5000 - lr: 0.0010\n",
            "Epoch 43/250\n",
            "20/19 [==============================] - 20s 979ms/step - loss: 13.2710 - acc: 0.6906 - val_loss: 13.3489 - val_acc: 0.5903 - lr: 0.0010\n",
            "Epoch 44/250\n",
            "20/19 [==============================] - 19s 942ms/step - loss: 13.3789 - acc: 0.6141 - val_loss: 14.8992 - val_acc: 0.5162 - lr: 0.0010\n",
            "Epoch 45/250\n",
            "20/19 [==============================] - 21s 1s/step - loss: 13.0397 - acc: 0.6469 - val_loss: 13.2394 - val_acc: 0.5220 - lr: 0.0010\n",
            "Epoch 46/250\n",
            "20/19 [==============================] - 19s 947ms/step - loss: 12.8228 - acc: 0.6859 - val_loss: 13.6496 - val_acc: 0.4815 - lr: 0.0010\n",
            "Epoch 47/250\n",
            "20/19 [==============================] - 20s 977ms/step - loss: 12.8874 - acc: 0.6875 - val_loss: 285.7664 - val_acc: 0.2708 - lr: 0.0010\n",
            "Epoch 48/250\n",
            "20/19 [==============================] - 20s 978ms/step - loss: 12.7398 - acc: 0.6562 - val_loss: 13.1789 - val_acc: 0.5081 - lr: 0.0010\n",
            "Epoch 49/250\n",
            "20/19 [==============================] - 18s 887ms/step - loss: 12.7902 - acc: 0.6438 - val_loss: 81.5387 - val_acc: 0.5938 - lr: 0.0010\n",
            "Epoch 50/250\n",
            "20/19 [==============================] - 17s 850ms/step - loss: 12.6314 - acc: 0.6406 - val_loss: 13.9690 - val_acc: 0.5683 - lr: 0.0010\n",
            "Epoch 51/250\n",
            "20/19 [==============================] - 17s 839ms/step - loss: 12.4524 - acc: 0.6344 - val_loss: 21.3936 - val_acc: 0.5127 - lr: 0.0010\n",
            "Epoch 52/250\n",
            "20/19 [==============================] - 17s 840ms/step - loss: 12.5297 - acc: 0.6391 - val_loss: 12.3224 - val_acc: 0.5509 - lr: 0.0010\n",
            "Epoch 53/250\n",
            "20/19 [==============================] - 17s 836ms/step - loss: 12.0786 - acc: 0.6672 - val_loss: 12.3546 - val_acc: 0.6609 - lr: 0.0010\n",
            "Epoch 54/250\n",
            "20/19 [==============================] - 17s 837ms/step - loss: 12.0552 - acc: 0.6641 - val_loss: 12.8368 - val_acc: 0.4062 - lr: 0.0010\n",
            "Epoch 55/250\n",
            "20/19 [==============================] - 17s 841ms/step - loss: 11.7604 - acc: 0.6250 - val_loss: 13.9294 - val_acc: 0.5116 - lr: 0.0010\n",
            "Epoch 56/250\n",
            "20/19 [==============================] - 17s 853ms/step - loss: 11.6727 - acc: 0.6422 - val_loss: 12.7413 - val_acc: 0.4051 - lr: 0.0010\n",
            "Epoch 57/250\n",
            "20/19 [==============================] - 17s 843ms/step - loss: 11.3083 - acc: 0.6453 - val_loss: 11.9983 - val_acc: 0.5058 - lr: 0.0010\n",
            "Epoch 58/250\n",
            "20/19 [==============================] - 17s 843ms/step - loss: 11.1209 - acc: 0.6469 - val_loss: 10.9773 - val_acc: 0.6759 - lr: 0.0010\n",
            "Epoch 59/250\n",
            "20/19 [==============================] - 17s 842ms/step - loss: 10.9039 - acc: 0.6625 - val_loss: 10.7451 - val_acc: 0.7083 - lr: 0.0010\n",
            "Epoch 60/250\n",
            "20/19 [==============================] - 17s 835ms/step - loss: 10.6846 - acc: 0.6625 - val_loss: 10.6147 - val_acc: 0.6863 - lr: 0.0010\n",
            "Epoch 61/250\n",
            "20/19 [==============================] - 17s 832ms/step - loss: 10.5389 - acc: 0.6406 - val_loss: 11.3385 - val_acc: 0.2847 - lr: 0.0010\n",
            "Epoch 62/250\n",
            "20/19 [==============================] - 17s 834ms/step - loss: 10.6905 - acc: 0.6731 - val_loss: 11.0856 - val_acc: 0.3819 - lr: 0.0010\n",
            "Epoch 63/250\n",
            "20/19 [==============================] - 17s 836ms/step - loss: 10.3169 - acc: 0.6844 - val_loss: 10.7953 - val_acc: 0.4375 - lr: 0.0010\n",
            "Epoch 64/250\n",
            "20/19 [==============================] - 17s 839ms/step - loss: 10.2927 - acc: 0.6422 - val_loss: 10.7872 - val_acc: 0.3148 - lr: 0.0010\n",
            "Epoch 65/250\n",
            "20/19 [==============================] - 17s 838ms/step - loss: 10.2505 - acc: 0.6506 - val_loss: 10.2111 - val_acc: 0.6157 - lr: 0.0010\n",
            "Epoch 66/250\n",
            "20/19 [==============================] - 17s 843ms/step - loss: 10.0987 - acc: 0.6442 - val_loss: 11.3736 - val_acc: 0.2303 - lr: 0.0010\n",
            "Epoch 67/250\n",
            "20/19 [==============================] - 17s 856ms/step - loss: 9.9728 - acc: 0.6859 - val_loss: 10.8284 - val_acc: 0.2593 - lr: 0.0010\n",
            "Epoch 68/250\n",
            "20/19 [==============================] - 17s 837ms/step - loss: 9.9780 - acc: 0.6609 - val_loss: 10.6665 - val_acc: 0.3426 - lr: 0.0010\n",
            "Epoch 69/250\n",
            "20/19 [==============================] - 17s 841ms/step - loss: 9.9990 - acc: 0.6250 - val_loss: 15.4225 - val_acc: 0.5139 - lr: 0.0010\n",
            "Epoch 70/250\n",
            "20/19 [==============================] - 17s 833ms/step - loss: 10.5465 - acc: 0.6156 - val_loss: 16999.3906 - val_acc: 0.5093 - lr: 0.0010\n",
            "Epoch 71/250\n",
            "20/19 [==============================] - 17s 834ms/step - loss: 10.4985 - acc: 0.6078 - val_loss: 1475.9929 - val_acc: 0.4560 - lr: 0.0010\n",
            "Epoch 72/250\n",
            "20/19 [==============================] - 17s 833ms/step - loss: 10.4930 - acc: 0.6453 - val_loss: 5076.7178 - val_acc: 0.3785 - lr: 0.0010\n",
            "Epoch 73/250\n",
            "20/19 [==============================] - 17s 838ms/step - loss: 10.2269 - acc: 0.6344 - val_loss: 189.0117 - val_acc: 0.4225 - lr: 0.0010\n",
            "Epoch 74/250\n",
            "20/19 [==============================] - 17s 828ms/step - loss: 9.9075 - acc: 0.6281 - val_loss: 14.3149 - val_acc: 0.3530 - lr: 0.0010\n",
            "Epoch 75/250\n",
            "20/19 [==============================] - 17s 835ms/step - loss: 9.6993 - acc: 0.5922 - val_loss: 10.2874 - val_acc: 0.3681 - lr: 0.0010\n",
            "Epoch 76/250\n",
            "20/19 [==============================] - 17s 835ms/step - loss: 9.4065 - acc: 0.6672 - val_loss: 9.3664 - val_acc: 0.6655 - lr: 0.0010\n",
            "Epoch 77/250\n",
            "20/19 [==============================] - 17s 835ms/step - loss: 9.2912 - acc: 0.6625 - val_loss: 9.7441 - val_acc: 0.5405 - lr: 0.0010\n",
            "Epoch 78/250\n",
            "20/19 [==============================] - 17s 836ms/step - loss: 9.0629 - acc: 0.6625 - val_loss: 9.4772 - val_acc: 0.5104 - lr: 0.0010\n",
            "Epoch 79/250\n",
            "20/19 [==============================] - 17s 833ms/step - loss: 9.0688 - acc: 0.6578 - val_loss: 9.3721 - val_acc: 0.5382 - lr: 0.0010\n",
            "Epoch 80/250\n",
            "20/19 [==============================] - 17s 837ms/step - loss: 9.1849 - acc: 0.6406 - val_loss: 9.9501 - val_acc: 0.3113 - lr: 0.0010\n",
            "Epoch 81/250\n",
            "20/19 [==============================] - 17s 831ms/step - loss: 9.0033 - acc: 0.6313 - val_loss: 9.6869 - val_acc: 0.3947 - lr: 0.0010\n",
            "Epoch 82/250\n",
            "20/19 [==============================] - 16s 824ms/step - loss: 8.9559 - acc: 0.6578 - val_loss: 9.6181 - val_acc: 0.3264 - lr: 1.0000e-04\n",
            "Epoch 83/250\n",
            "20/19 [==============================] - 17s 831ms/step - loss: 8.8369 - acc: 0.6656 - val_loss: 9.6892 - val_acc: 0.3079 - lr: 1.0000e-04\n",
            "Epoch 84/250\n",
            "20/19 [==============================] - 17s 829ms/step - loss: 8.8246 - acc: 0.6938 - val_loss: 9.7562 - val_acc: 0.2662 - lr: 1.0000e-04\n",
            "Epoch 85/250\n",
            "20/19 [==============================] - 17s 832ms/step - loss: 8.9011 - acc: 0.6562 - val_loss: 9.6309 - val_acc: 0.2951 - lr: 1.0000e-04\n",
            "Epoch 86/250\n",
            "20/19 [==============================] - 17s 859ms/step - loss: 8.7076 - acc: 0.6844 - val_loss: 9.5282 - val_acc: 0.3264 - lr: 1.0000e-04\n",
            "Epoch 87/250\n",
            "20/19 [==============================] - 17s 872ms/step - loss: 8.7513 - acc: 0.6490 - val_loss: 9.2973 - val_acc: 0.4363 - lr: 1.0000e-04\n",
            "Epoch 88/250\n",
            "20/19 [==============================] - 17s 851ms/step - loss: 8.6373 - acc: 0.6734 - val_loss: 9.3357 - val_acc: 0.4109 - lr: 1.0000e-04\n",
            "Epoch 89/250\n",
            "20/19 [==============================] - 17s 841ms/step - loss: 8.6186 - acc: 0.6828 - val_loss: 9.3039 - val_acc: 0.4201 - lr: 1.0000e-04\n",
            "Epoch 90/250\n",
            "20/19 [==============================] - 17s 837ms/step - loss: 8.6183 - acc: 0.6827 - val_loss: 9.4391 - val_acc: 0.3715 - lr: 1.0000e-04\n",
            "Epoch 91/250\n",
            "20/19 [==============================] - 17s 834ms/step - loss: 8.7000 - acc: 0.6719 - val_loss: 9.6531 - val_acc: 0.3067 - lr: 1.0000e-04\n",
            "Epoch 92/250\n",
            "20/19 [==============================] - 17s 832ms/step - loss: 8.5905 - acc: 0.6672 - val_loss: 9.3113 - val_acc: 0.3958 - lr: 1.0000e-04\n",
            "Epoch 93/250\n",
            "20/19 [==============================] - 17s 825ms/step - loss: 8.6289 - acc: 0.6609 - val_loss: 8.7007 - val_acc: 0.6412 - lr: 1.0000e-04\n",
            "Epoch 94/250\n",
            "20/19 [==============================] - 16s 824ms/step - loss: 8.5901 - acc: 0.6828 - val_loss: 8.6544 - val_acc: 0.6609 - lr: 1.0000e-04\n",
            "Epoch 95/250\n",
            "20/19 [==============================] - 17s 828ms/step - loss: 8.5969 - acc: 0.6500 - val_loss: 9.0985 - val_acc: 0.4630 - lr: 1.0000e-04\n",
            "Epoch 96/250\n",
            "20/19 [==============================] - 17s 830ms/step - loss: 8.4598 - acc: 0.7125 - val_loss: 8.8435 - val_acc: 0.5683 - lr: 1.0000e-04\n",
            "Epoch 97/250\n",
            "20/19 [==============================] - 16s 823ms/step - loss: 8.4872 - acc: 0.6859 - val_loss: 8.6969 - val_acc: 0.6238 - lr: 1.0000e-04\n",
            "Epoch 98/250\n",
            "20/19 [==============================] - 16s 822ms/step - loss: 8.5011 - acc: 0.6734 - val_loss: 8.8676 - val_acc: 0.5417 - lr: 1.0000e-04\n",
            "Epoch 99/250\n",
            "20/19 [==============================] - 16s 818ms/step - loss: 8.4745 - acc: 0.6922 - val_loss: 8.8305 - val_acc: 0.5567 - lr: 1.0000e-04\n",
            "Epoch 100/250\n",
            "20/19 [==============================] - 17s 829ms/step - loss: 8.4523 - acc: 0.6656 - val_loss: 9.0508 - val_acc: 0.4815 - lr: 1.0000e-04\n",
            "Epoch 101/250\n",
            "20/19 [==============================] - 16s 816ms/step - loss: 8.3889 - acc: 0.6969 - val_loss: 8.3996 - val_acc: 0.7141 - lr: 1.0000e-04\n",
            "Epoch 102/250\n",
            "20/19 [==============================] - 17s 835ms/step - loss: 8.3864 - acc: 0.6891 - val_loss: 8.4155 - val_acc: 0.6933 - lr: 1.0000e-04\n",
            "Epoch 103/250\n",
            "20/19 [==============================] - 17s 831ms/step - loss: 8.3521 - acc: 0.6906 - val_loss: 8.4027 - val_acc: 0.6806 - lr: 1.0000e-04\n",
            "Epoch 104/250\n",
            "20/19 [==============================] - 17s 827ms/step - loss: 8.4135 - acc: 0.6594 - val_loss: 8.4276 - val_acc: 0.6806 - lr: 1.0000e-04\n",
            "Epoch 105/250\n",
            "20/19 [==============================] - 16s 814ms/step - loss: 8.3402 - acc: 0.6797 - val_loss: 8.3744 - val_acc: 0.6979 - lr: 1.0000e-04\n",
            "Epoch 106/250\n",
            "20/19 [==============================] - 16s 817ms/step - loss: 8.3572 - acc: 0.6715 - val_loss: 8.3656 - val_acc: 0.6817 - lr: 1.0000e-04\n",
            "Epoch 107/250\n",
            "20/19 [==============================] - 16s 811ms/step - loss: 8.3779 - acc: 0.6625 - val_loss: 8.3196 - val_acc: 0.6863 - lr: 1.0000e-04\n",
            "Epoch 108/250\n",
            "20/19 [==============================] - 16s 809ms/step - loss: 8.2389 - acc: 0.7000 - val_loss: 8.4307 - val_acc: 0.6586 - lr: 1.0000e-04\n",
            "Epoch 109/250\n",
            "20/19 [==============================] - 16s 810ms/step - loss: 8.2684 - acc: 0.6844 - val_loss: 8.3666 - val_acc: 0.6620 - lr: 1.0000e-04\n",
            "Epoch 110/250\n",
            "20/19 [==============================] - 16s 804ms/step - loss: 8.2016 - acc: 0.7115 - val_loss: 8.2122 - val_acc: 0.7292 - lr: 1.0000e-04\n",
            "Epoch 111/250\n",
            "20/19 [==============================] - 16s 818ms/step - loss: 8.2495 - acc: 0.6781 - val_loss: 8.3059 - val_acc: 0.6655 - lr: 1.0000e-04\n",
            "Epoch 112/250\n",
            "20/19 [==============================] - 16s 808ms/step - loss: 8.1774 - acc: 0.6923 - val_loss: 8.1954 - val_acc: 0.7106 - lr: 1.0000e-04\n",
            "Epoch 113/250\n",
            "20/19 [==============================] - 16s 817ms/step - loss: 8.1488 - acc: 0.7297 - val_loss: 8.2831 - val_acc: 0.6713 - lr: 1.0000e-04\n",
            "Epoch 114/250\n",
            "20/19 [==============================] - 16s 817ms/step - loss: 8.1362 - acc: 0.6781 - val_loss: 8.9766 - val_acc: 0.4468 - lr: 1.0000e-04\n",
            "Epoch 115/250\n",
            "20/19 [==============================] - 16s 822ms/step - loss: 8.2826 - acc: 0.6438 - val_loss: 8.1487 - val_acc: 0.7014 - lr: 1.0000e-04\n",
            "Epoch 116/250\n",
            "20/19 [==============================] - 16s 807ms/step - loss: 8.2331 - acc: 0.6625 - val_loss: 8.1624 - val_acc: 0.6794 - lr: 1.0000e-04\n",
            "Epoch 117/250\n",
            "20/19 [==============================] - 16s 810ms/step - loss: 8.1633 - acc: 0.6859 - val_loss: 8.0654 - val_acc: 0.7245 - lr: 1.0000e-04\n",
            "Epoch 118/250\n",
            "20/19 [==============================] - 16s 807ms/step - loss: 8.1564 - acc: 0.6641 - val_loss: 8.1340 - val_acc: 0.6736 - lr: 1.0000e-04\n",
            "Epoch 119/250\n",
            "20/19 [==============================] - 16s 809ms/step - loss: 8.1067 - acc: 0.7000 - val_loss: 8.1652 - val_acc: 0.6713 - lr: 1.0000e-04\n",
            "Epoch 120/250\n",
            "20/19 [==============================] - 16s 811ms/step - loss: 8.0387 - acc: 0.7016 - val_loss: 8.6201 - val_acc: 0.4884 - lr: 1.0000e-04\n",
            "Epoch 121/250\n",
            "20/19 [==============================] - 16s 820ms/step - loss: 8.0492 - acc: 0.6875 - val_loss: 8.6165 - val_acc: 0.4896 - lr: 1.0000e-04\n",
            "Epoch 122/250\n",
            "20/19 [==============================] - 16s 809ms/step - loss: 8.0615 - acc: 0.6715 - val_loss: 8.4606 - val_acc: 0.5544 - lr: 1.0000e-05\n",
            "Epoch 123/250\n",
            "20/19 [==============================] - 16s 802ms/step - loss: 8.0599 - acc: 0.6907 - val_loss: 8.3981 - val_acc: 0.5718 - lr: 1.0000e-05\n",
            "Epoch 124/250\n",
            "20/19 [==============================] - 18s 877ms/step - loss: 8.0612 - acc: 0.6875 - val_loss: 8.2917 - val_acc: 0.6076 - lr: 1.0000e-05\n",
            "Epoch 125/250\n",
            "20/19 [==============================] - 20s 1s/step - loss: 8.0419 - acc: 0.7109 - val_loss: 8.2601 - val_acc: 0.6424 - lr: 1.0000e-05\n",
            "Epoch 126/250\n",
            "20/19 [==============================] - 17s 867ms/step - loss: 7.9698 - acc: 0.7266 - val_loss: 8.1604 - val_acc: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 127/250\n",
            "20/19 [==============================] - 18s 880ms/step - loss: 8.0256 - acc: 0.7219 - val_loss: 8.1075 - val_acc: 0.6817 - lr: 1.0000e-05\n",
            "Epoch 128/250\n",
            "20/19 [==============================] - 20s 978ms/step - loss: 8.0639 - acc: 0.7031 - val_loss: 8.0469 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "Epoch 129/250\n",
            "20/19 [==============================] - 17s 837ms/step - loss: 7.9986 - acc: 0.7078 - val_loss: 8.0825 - val_acc: 0.6944 - lr: 1.0000e-05\n",
            "Epoch 130/250\n",
            "20/19 [==============================] - 19s 936ms/step - loss: 8.0590 - acc: 0.6828 - val_loss: 8.0716 - val_acc: 0.6979 - lr: 1.0000e-05\n",
            "Epoch 131/250\n",
            "20/19 [==============================] - 16s 816ms/step - loss: 7.9430 - acc: 0.7250 - val_loss: 8.0975 - val_acc: 0.6782 - lr: 1.0000e-05\n",
            "Epoch 132/250\n",
            "20/19 [==============================] - 16s 810ms/step - loss: 7.9960 - acc: 0.7125 - val_loss: 8.0770 - val_acc: 0.6852 - lr: 1.0000e-05\n",
            "Epoch 133/250\n",
            "20/19 [==============================] - 16s 814ms/step - loss: 7.9982 - acc: 0.7234 - val_loss: 8.0427 - val_acc: 0.6910 - lr: 1.0000e-05\n",
            "Epoch 134/250\n",
            "20/19 [==============================] - 17s 830ms/step - loss: 8.0323 - acc: 0.6844 - val_loss: 8.0367 - val_acc: 0.6956 - lr: 1.0000e-05\n",
            "Epoch 135/250\n",
            "20/19 [==============================] - 16s 818ms/step - loss: 8.0863 - acc: 0.6797 - val_loss: 8.0473 - val_acc: 0.6944 - lr: 1.0000e-05\n",
            "Epoch 136/250\n",
            "20/19 [==============================] - 16s 813ms/step - loss: 8.0003 - acc: 0.7016 - val_loss: 8.1108 - val_acc: 0.6701 - lr: 1.0000e-05\n",
            "Epoch 137/250\n",
            "20/19 [==============================] - 16s 822ms/step - loss: 7.9732 - acc: 0.7031 - val_loss: 8.0406 - val_acc: 0.6910 - lr: 1.0000e-05\n",
            "Epoch 138/250\n",
            "20/19 [==============================] - 17s 827ms/step - loss: 8.0888 - acc: 0.6641 - val_loss: 8.0746 - val_acc: 0.6748 - lr: 1.0000e-05\n",
            "Epoch 139/250\n",
            "20/19 [==============================] - 16s 821ms/step - loss: 8.0142 - acc: 0.6875 - val_loss: 7.9961 - val_acc: 0.6968 - lr: 1.0000e-05\n",
            "Epoch 140/250\n",
            "20/19 [==============================] - 16s 814ms/step - loss: 8.0440 - acc: 0.6828 - val_loss: 8.0070 - val_acc: 0.7037 - lr: 1.0000e-05\n",
            "Epoch 141/250\n",
            "20/19 [==============================] - 16s 815ms/step - loss: 8.0036 - acc: 0.7063 - val_loss: 8.0047 - val_acc: 0.6991 - lr: 1.0000e-05\n",
            "Epoch 142/250\n",
            "20/19 [==============================] - 16s 812ms/step - loss: 7.9991 - acc: 0.6969 - val_loss: 8.0189 - val_acc: 0.7060 - lr: 1.0000e-05\n",
            "Epoch 143/250\n",
            "20/19 [==============================] - 16s 818ms/step - loss: 7.9778 - acc: 0.7000 - val_loss: 7.9837 - val_acc: 0.7130 - lr: 1.0000e-05\n",
            "Epoch 144/250\n",
            "20/19 [==============================] - 16s 812ms/step - loss: 8.0008 - acc: 0.6953 - val_loss: 8.0450 - val_acc: 0.6817 - lr: 1.0000e-05\n",
            "Epoch 145/250\n",
            "20/19 [==============================] - 16s 823ms/step - loss: 7.9505 - acc: 0.7260 - val_loss: 8.0468 - val_acc: 0.6944 - lr: 1.0000e-05\n",
            "Epoch 146/250\n",
            "20/19 [==============================] - 16s 823ms/step - loss: 7.9997 - acc: 0.6891 - val_loss: 7.9779 - val_acc: 0.7188 - lr: 1.0000e-05\n",
            "Epoch 147/250\n",
            "20/19 [==============================] - 16s 824ms/step - loss: 8.0059 - acc: 0.6922 - val_loss: 8.0177 - val_acc: 0.7072 - lr: 1.0000e-05\n",
            "Epoch 148/250\n",
            "20/19 [==============================] - 17s 826ms/step - loss: 7.9626 - acc: 0.6875 - val_loss: 7.9969 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 149/250\n",
            "20/19 [==============================] - 16s 825ms/step - loss: 7.9398 - acc: 0.7188 - val_loss: 8.0169 - val_acc: 0.6956 - lr: 1.0000e-05\n",
            "Epoch 150/250\n",
            "20/19 [==============================] - 16s 816ms/step - loss: 8.0062 - acc: 0.6750 - val_loss: 7.9876 - val_acc: 0.6979 - lr: 1.0000e-05\n",
            "Epoch 151/250\n",
            "20/19 [==============================] - 16s 824ms/step - loss: 8.0399 - acc: 0.6578 - val_loss: 8.0263 - val_acc: 0.6979 - lr: 1.0000e-05\n",
            "Epoch 152/250\n",
            "20/19 [==============================] - 16s 822ms/step - loss: 7.9248 - acc: 0.7344 - val_loss: 7.9967 - val_acc: 0.6956 - lr: 1.0000e-05\n",
            "Epoch 153/250\n",
            "20/19 [==============================] - 16s 814ms/step - loss: 7.9930 - acc: 0.7016 - val_loss: 7.9825 - val_acc: 0.7037 - lr: 1.0000e-05\n",
            "Epoch 154/250\n",
            "20/19 [==============================] - 16s 814ms/step - loss: 8.0398 - acc: 0.6875 - val_loss: 8.0420 - val_acc: 0.6782 - lr: 1.0000e-05\n",
            "Epoch 155/250\n",
            "20/19 [==============================] - 17s 826ms/step - loss: 7.9248 - acc: 0.7156 - val_loss: 7.9496 - val_acc: 0.7222 - lr: 1.0000e-05\n",
            "Epoch 156/250\n",
            "20/19 [==============================] - 17s 828ms/step - loss: 7.9356 - acc: 0.6984 - val_loss: 8.0241 - val_acc: 0.7060 - lr: 1.0000e-05\n",
            "Epoch 157/250\n",
            "20/19 [==============================] - 17s 832ms/step - loss: 7.9702 - acc: 0.6875 - val_loss: 7.9953 - val_acc: 0.7141 - lr: 1.0000e-05\n",
            "Epoch 158/250\n",
            "20/19 [==============================] - 17s 826ms/step - loss: 7.9685 - acc: 0.6734 - val_loss: 7.9970 - val_acc: 0.6863 - lr: 1.0000e-05\n",
            "Epoch 159/250\n",
            "20/19 [==============================] - 17s 830ms/step - loss: 7.9788 - acc: 0.6953 - val_loss: 7.9443 - val_acc: 0.7141 - lr: 1.0000e-05\n",
            "Epoch 160/250\n",
            "20/19 [==============================] - 16s 823ms/step - loss: 7.9888 - acc: 0.6609 - val_loss: 7.9658 - val_acc: 0.7002 - lr: 1.0000e-05\n",
            "Epoch 161/250\n",
            "20/19 [==============================] - 16s 825ms/step - loss: 7.9392 - acc: 0.6938 - val_loss: 7.9568 - val_acc: 0.7025 - lr: 1.0000e-05\n",
            "Epoch 162/250\n",
            "20/19 [==============================] - 17s 826ms/step - loss: 7.9615 - acc: 0.6734 - val_loss: 7.9536 - val_acc: 0.7049 - lr: 1.0000e-06\n",
            "Epoch 163/250\n",
            "20/19 [==============================] - 17s 828ms/step - loss: 8.0058 - acc: 0.6703 - val_loss: 8.0141 - val_acc: 0.6725 - lr: 1.0000e-06\n",
            "Epoch 164/250\n",
            "20/19 [==============================] - 17s 825ms/step - loss: 7.9733 - acc: 0.6828 - val_loss: 8.0080 - val_acc: 0.6898 - lr: 1.0000e-06\n",
            "Epoch 165/250\n",
            "20/19 [==============================] - 16s 824ms/step - loss: 7.9455 - acc: 0.6859 - val_loss: 7.9942 - val_acc: 0.6921 - lr: 1.0000e-06\n",
            "Epoch 166/250\n",
            "20/19 [==============================] - 16s 824ms/step - loss: 7.9716 - acc: 0.6906 - val_loss: 7.9951 - val_acc: 0.7002 - lr: 1.0000e-06\n",
            "Epoch 167/250\n",
            "20/19 [==============================] - 17s 827ms/step - loss: 7.9850 - acc: 0.6891 - val_loss: 7.9517 - val_acc: 0.7014 - lr: 1.0000e-06\n",
            "Epoch 168/250\n",
            "20/19 [==============================] - 16s 817ms/step - loss: 8.0029 - acc: 0.6812 - val_loss: 7.9329 - val_acc: 0.7222 - lr: 1.0000e-06\n",
            "Epoch 169/250\n",
            "20/19 [==============================] - 16s 813ms/step - loss: 7.9961 - acc: 0.6651 - val_loss: 7.9657 - val_acc: 0.7002 - lr: 1.0000e-06\n",
            "Epoch 170/250\n",
            "20/19 [==============================] - 16s 818ms/step - loss: 7.9161 - acc: 0.7047 - val_loss: 7.9635 - val_acc: 0.6840 - lr: 1.0000e-06\n",
            "Epoch 171/250\n",
            "20/19 [==============================] - 16s 820ms/step - loss: 7.8552 - acc: 0.7328 - val_loss: 7.9954 - val_acc: 0.6887 - lr: 1.0000e-06\n",
            "Epoch 172/250\n",
            "20/19 [==============================] - 17s 826ms/step - loss: 7.9489 - acc: 0.6797 - val_loss: 8.0406 - val_acc: 0.6944 - lr: 1.0000e-06\n",
            "Epoch 173/250\n",
            "20/19 [==============================] - 16s 820ms/step - loss: 7.8991 - acc: 0.7094 - val_loss: 7.9712 - val_acc: 0.7083 - lr: 1.0000e-06\n",
            "Epoch 174/250\n",
            "20/19 [==============================] - 16s 822ms/step - loss: 7.8893 - acc: 0.7172 - val_loss: 7.9755 - val_acc: 0.6968 - lr: 1.0000e-06\n",
            "Epoch 175/250\n",
            "20/19 [==============================] - 16s 823ms/step - loss: 7.9760 - acc: 0.6734 - val_loss: 7.9466 - val_acc: 0.7118 - lr: 1.0000e-06\n",
            "Epoch 176/250\n",
            "20/19 [==============================] - 16s 823ms/step - loss: 7.9311 - acc: 0.7047 - val_loss: 7.9961 - val_acc: 0.7037 - lr: 1.0000e-06\n",
            "Epoch 177/250\n",
            "20/19 [==============================] - 17s 833ms/step - loss: 7.9184 - acc: 0.6984 - val_loss: 7.9466 - val_acc: 0.7095 - lr: 1.0000e-06\n",
            "Epoch 178/250\n",
            "20/19 [==============================] - 17s 825ms/step - loss: 8.0410 - acc: 0.6594 - val_loss: 7.9735 - val_acc: 0.6968 - lr: 1.0000e-06\n",
            "Epoch 179/250\n",
            "20/19 [==============================] - 16s 817ms/step - loss: 7.9782 - acc: 0.6828 - val_loss: 7.9674 - val_acc: 0.7083 - lr: 1.0000e-06\n",
            "Epoch 180/250\n",
            "20/19 [==============================] - 17s 826ms/step - loss: 7.9147 - acc: 0.7078 - val_loss: 8.0128 - val_acc: 0.6979 - lr: 1.0000e-06\n",
            "Epoch 181/250\n",
            "20/19 [==============================] - 16s 822ms/step - loss: 8.0140 - acc: 0.6687 - val_loss: 7.9884 - val_acc: 0.6875 - lr: 1.0000e-06\n",
            "Epoch 182/250\n",
            "20/19 [==============================] - 17s 829ms/step - loss: 7.9566 - acc: 0.7000 - val_loss: 7.9485 - val_acc: 0.7141 - lr: 5.0000e-07\n",
            "Epoch 183/250\n",
            "20/19 [==============================] - 16s 822ms/step - loss: 7.9733 - acc: 0.6656 - val_loss: 7.9859 - val_acc: 0.7014 - lr: 5.0000e-07\n",
            "Epoch 184/250\n",
            "20/19 [==============================] - 17s 829ms/step - loss: 7.8835 - acc: 0.7203 - val_loss: 7.9481 - val_acc: 0.7211 - lr: 5.0000e-07\n",
            "Epoch 185/250\n",
            "20/19 [==============================] - 17s 831ms/step - loss: 8.0089 - acc: 0.6797 - val_loss: 8.0007 - val_acc: 0.6968 - lr: 5.0000e-07\n",
            "Epoch 186/250\n",
            "20/19 [==============================] - 16s 817ms/step - loss: 7.9414 - acc: 0.6812 - val_loss: 8.0010 - val_acc: 0.6979 - lr: 5.0000e-07\n",
            "Epoch 187/250\n",
            "20/19 [==============================] - 16s 818ms/step - loss: 7.9522 - acc: 0.6969 - val_loss: 7.9602 - val_acc: 0.7095 - lr: 5.0000e-07\n",
            "Epoch 188/250\n",
            "20/19 [==============================] - 16s 820ms/step - loss: 7.9731 - acc: 0.6781 - val_loss: 8.0107 - val_acc: 0.6852 - lr: 5.0000e-07\n",
            "Epoch 189/250\n",
            "20/19 [==============================] - 16s 815ms/step - loss: 7.9461 - acc: 0.6922 - val_loss: 7.9485 - val_acc: 0.7083 - lr: 5.0000e-07\n",
            "Epoch 190/250\n",
            "20/19 [==============================] - 16s 819ms/step - loss: 7.9613 - acc: 0.7047 - val_loss: 7.9761 - val_acc: 0.6910 - lr: 5.0000e-07\n",
            "Epoch 191/250\n",
            "20/19 [==============================] - 17s 837ms/step - loss: 7.9328 - acc: 0.7188 - val_loss: 8.0120 - val_acc: 0.6829 - lr: 5.0000e-07\n",
            "Epoch 192/250\n",
            "20/19 [==============================] - 16s 816ms/step - loss: 7.9258 - acc: 0.6875 - val_loss: 7.9560 - val_acc: 0.7060 - lr: 5.0000e-07\n",
            "Epoch 193/250\n",
            "20/19 [==============================] - 17s 831ms/step - loss: 7.9338 - acc: 0.7000 - val_loss: 7.9840 - val_acc: 0.6921 - lr: 5.0000e-07\n",
            "Epoch 194/250\n",
            "20/19 [==============================] - 16s 817ms/step - loss: 8.0300 - acc: 0.6766 - val_loss: 7.9570 - val_acc: 0.7060 - lr: 5.0000e-07\n",
            "Epoch 195/250\n",
            "20/19 [==============================] - 17s 827ms/step - loss: 7.9366 - acc: 0.7031 - val_loss: 7.9760 - val_acc: 0.7037 - lr: 5.0000e-07\n",
            "Epoch 196/250\n",
            "20/19 [==============================] - 16s 817ms/step - loss: 7.9726 - acc: 0.6859 - val_loss: 8.0074 - val_acc: 0.6794 - lr: 5.0000e-07\n",
            "Epoch 197/250\n",
            "20/19 [==============================] - 17s 828ms/step - loss: 7.9608 - acc: 0.6828 - val_loss: 7.9785 - val_acc: 0.6921 - lr: 5.0000e-07\n",
            "Epoch 198/250\n",
            "20/19 [==============================] - 17s 825ms/step - loss: 7.9623 - acc: 0.6938 - val_loss: 7.9494 - val_acc: 0.7083 - lr: 5.0000e-07\n",
            "Epoch 199/250\n",
            "20/19 [==============================] - 17s 833ms/step - loss: 7.9398 - acc: 0.7016 - val_loss: 7.9536 - val_acc: 0.6968 - lr: 5.0000e-07\n",
            "Epoch 200/250\n",
            "20/19 [==============================] - 16s 823ms/step - loss: 7.9730 - acc: 0.6891 - val_loss: 7.9914 - val_acc: 0.6863 - lr: 5.0000e-07\n",
            "Epoch 201/250\n",
            "20/19 [==============================] - 16s 822ms/step - loss: 7.9397 - acc: 0.6906 - val_loss: 7.9940 - val_acc: 0.6933 - lr: 5.0000e-07\n",
            "Epoch 202/250\n",
            "20/19 [==============================] - 17s 826ms/step - loss: 7.9606 - acc: 0.6969 - val_loss: 7.9631 - val_acc: 0.7106 - lr: 5.0000e-07\n",
            "Epoch 203/250\n",
            "20/19 [==============================] - 16s 813ms/step - loss: 7.9450 - acc: 0.6923 - val_loss: 8.0077 - val_acc: 0.6875 - lr: 5.0000e-07\n",
            "Epoch 204/250\n",
            "20/19 [==============================] - 17s 830ms/step - loss: 7.9087 - acc: 0.7203 - val_loss: 7.9758 - val_acc: 0.6933 - lr: 5.0000e-07\n",
            "Epoch 205/250\n",
            "20/19 [==============================] - 16s 821ms/step - loss: 8.0107 - acc: 0.6594 - val_loss: 7.9411 - val_acc: 0.7211 - lr: 5.0000e-07\n",
            "Epoch 206/250\n",
            "20/19 [==============================] - 16s 816ms/step - loss: 8.0172 - acc: 0.6641 - val_loss: 7.9499 - val_acc: 0.6921 - lr: 5.0000e-07\n",
            "Epoch 207/250\n",
            "20/19 [==============================] - 18s 903ms/step - loss: 7.9090 - acc: 0.7141 - val_loss: 7.9665 - val_acc: 0.6852 - lr: 5.0000e-07\n",
            "Epoch 208/250\n",
            "20/19 [==============================] - 18s 898ms/step - loss: 7.9018 - acc: 0.7063 - val_loss: 7.9835 - val_acc: 0.7037 - lr: 5.0000e-07\n",
            "Epoch 209/250\n",
            "20/19 [==============================] - 18s 901ms/step - loss: 7.9353 - acc: 0.6969 - val_loss: 7.9494 - val_acc: 0.7095 - lr: 5.0000e-07\n",
            "Epoch 210/250\n",
            "20/19 [==============================] - 18s 891ms/step - loss: 7.8964 - acc: 0.6922 - val_loss: 7.9758 - val_acc: 0.7049 - lr: 5.0000e-07\n",
            "Epoch 211/250\n",
            "20/19 [==============================] - 18s 891ms/step - loss: 7.9138 - acc: 0.6984 - val_loss: 7.9780 - val_acc: 0.7095 - lr: 5.0000e-07\n",
            "Epoch 212/250\n",
            "20/19 [==============================] - 18s 904ms/step - loss: 7.9906 - acc: 0.6875 - val_loss: 7.9656 - val_acc: 0.7049 - lr: 5.0000e-07\n",
            "Epoch 213/250\n",
            "20/19 [==============================] - 16s 821ms/step - loss: 8.0033 - acc: 0.6703 - val_loss: 8.1034 - val_acc: 0.6493 - lr: 5.0000e-07\n",
            "Epoch 214/250\n",
            "20/19 [==============================] - 17s 827ms/step - loss: 7.9764 - acc: 0.6969 - val_loss: 7.9906 - val_acc: 0.6979 - lr: 5.0000e-07\n",
            "Epoch 215/250\n",
            "20/19 [==============================] - 17s 826ms/step - loss: 7.9482 - acc: 0.6891 - val_loss: 7.9718 - val_acc: 0.6771 - lr: 5.0000e-07\n",
            "Epoch 216/250\n",
            "20/19 [==============================] - 19s 931ms/step - loss: 7.9477 - acc: 0.6969 - val_loss: 7.9644 - val_acc: 0.7037 - lr: 5.0000e-07\n",
            "Epoch 217/250\n",
            "20/19 [==============================] - 17s 826ms/step - loss: 7.9029 - acc: 0.7078 - val_loss: 7.9667 - val_acc: 0.7106 - lr: 5.0000e-07\n",
            "Epoch 218/250\n",
            "20/19 [==============================] - 16s 825ms/step - loss: 7.9325 - acc: 0.7047 - val_loss: 7.9934 - val_acc: 0.6887 - lr: 5.0000e-07\n",
            "Epoch 219/250\n",
            "20/19 [==============================] - 16s 821ms/step - loss: 7.8806 - acc: 0.7125 - val_loss: 7.9901 - val_acc: 0.6968 - lr: 5.0000e-07\n",
            "Epoch 220/250\n",
            "20/19 [==============================] - 16s 822ms/step - loss: 7.9713 - acc: 0.7000 - val_loss: 8.0050 - val_acc: 0.6991 - lr: 5.0000e-07\n",
            "Epoch 221/250\n",
            "20/19 [==============================] - 16s 821ms/step - loss: 7.9592 - acc: 0.6859 - val_loss: 7.9310 - val_acc: 0.7037 - lr: 5.0000e-07\n",
            "Epoch 222/250\n",
            "20/19 [==============================] - 16s 822ms/step - loss: 7.9251 - acc: 0.6922 - val_loss: 7.9872 - val_acc: 0.7072 - lr: 5.0000e-07\n",
            "Epoch 223/250\n",
            "20/19 [==============================] - 17s 829ms/step - loss: 7.9305 - acc: 0.6969 - val_loss: 7.8945 - val_acc: 0.7280 - lr: 5.0000e-07\n",
            "Epoch 224/250\n",
            "20/19 [==============================] - 17s 848ms/step - loss: 8.0032 - acc: 0.6734 - val_loss: 7.9437 - val_acc: 0.6979 - lr: 5.0000e-07\n",
            "Epoch 225/250\n",
            "20/19 [==============================] - 17s 848ms/step - loss: 7.9211 - acc: 0.7109 - val_loss: 8.0169 - val_acc: 0.6806 - lr: 5.0000e-07\n",
            "Epoch 226/250\n",
            "20/19 [==============================] - 17s 853ms/step - loss: 7.9572 - acc: 0.6812 - val_loss: 7.9374 - val_acc: 0.7072 - lr: 5.0000e-07\n",
            "Epoch 227/250\n",
            "20/19 [==============================] - 17s 861ms/step - loss: 7.9168 - acc: 0.7109 - val_loss: 7.9708 - val_acc: 0.7025 - lr: 5.0000e-07\n",
            "Epoch 228/250\n",
            "20/19 [==============================] - 17s 852ms/step - loss: 7.9977 - acc: 0.6797 - val_loss: 7.9708 - val_acc: 0.6863 - lr: 5.0000e-07\n",
            "Epoch 229/250\n",
            "20/19 [==============================] - 17s 831ms/step - loss: 7.9267 - acc: 0.6844 - val_loss: 7.9409 - val_acc: 0.7083 - lr: 5.0000e-07\n",
            "Epoch 230/250\n",
            "20/19 [==============================] - 17s 833ms/step - loss: 7.8601 - acc: 0.7281 - val_loss: 8.0318 - val_acc: 0.6829 - lr: 5.0000e-07\n",
            "Epoch 231/250\n",
            "20/19 [==============================] - 17s 855ms/step - loss: 7.9476 - acc: 0.6797 - val_loss: 8.0189 - val_acc: 0.6759 - lr: 5.0000e-07\n",
            "Epoch 232/250\n",
            "20/19 [==============================] - 17s 856ms/step - loss: 7.8879 - acc: 0.7219 - val_loss: 7.9988 - val_acc: 0.6944 - lr: 5.0000e-07\n",
            "Epoch 233/250\n",
            "20/19 [==============================] - 17s 839ms/step - loss: 7.9619 - acc: 0.6750 - val_loss: 7.9624 - val_acc: 0.7002 - lr: 5.0000e-07\n",
            "Epoch 234/250\n",
            "20/19 [==============================] - 17s 837ms/step - loss: 7.9022 - acc: 0.6750 - val_loss: 7.9239 - val_acc: 0.7118 - lr: 5.0000e-07\n",
            "Epoch 235/250\n",
            "20/19 [==============================] - 17s 828ms/step - loss: 7.9772 - acc: 0.6687 - val_loss: 7.9968 - val_acc: 0.6829 - lr: 5.0000e-07\n",
            "Epoch 236/250\n",
            "20/19 [==============================] - 17s 842ms/step - loss: 7.8831 - acc: 0.7016 - val_loss: 8.0228 - val_acc: 0.6829 - lr: 5.0000e-07\n",
            "Epoch 237/250\n",
            "20/19 [==============================] - 17s 830ms/step - loss: 7.8775 - acc: 0.7266 - val_loss: 7.9155 - val_acc: 0.7315 - lr: 5.0000e-07\n",
            "Epoch 238/250\n",
            "20/19 [==============================] - 17s 827ms/step - loss: 7.9468 - acc: 0.6781 - val_loss: 7.9755 - val_acc: 0.7072 - lr: 5.0000e-07\n",
            "Epoch 239/250\n",
            "20/19 [==============================] - 17s 826ms/step - loss: 8.0100 - acc: 0.6625 - val_loss: 7.9439 - val_acc: 0.7072 - lr: 5.0000e-07\n",
            "Epoch 240/250\n",
            "20/19 [==============================] - 17s 841ms/step - loss: 7.9025 - acc: 0.7172 - val_loss: 7.9753 - val_acc: 0.6979 - lr: 5.0000e-07\n",
            "Epoch 241/250\n",
            "20/19 [==============================] - 17s 830ms/step - loss: 7.9130 - acc: 0.7047 - val_loss: 7.9890 - val_acc: 0.6921 - lr: 5.0000e-07\n",
            "Epoch 242/250\n",
            "20/19 [==============================] - 17s 838ms/step - loss: 7.9917 - acc: 0.6562 - val_loss: 7.9867 - val_acc: 0.6944 - lr: 5.0000e-07\n",
            "Epoch 243/250\n",
            "20/19 [==============================] - 17s 829ms/step - loss: 7.8734 - acc: 0.7172 - val_loss: 7.9625 - val_acc: 0.6933 - lr: 5.0000e-07\n",
            "Epoch 244/250\n",
            "20/19 [==============================] - 17s 841ms/step - loss: 7.9449 - acc: 0.6969 - val_loss: 7.9528 - val_acc: 0.7153 - lr: 5.0000e-07\n",
            "Epoch 245/250\n",
            "20/19 [==============================] - 17s 841ms/step - loss: 7.9198 - acc: 0.7172 - val_loss: 7.9396 - val_acc: 0.7234 - lr: 5.0000e-07\n",
            "Epoch 246/250\n",
            "20/19 [==============================] - 17s 853ms/step - loss: 7.9681 - acc: 0.6828 - val_loss: 7.9138 - val_acc: 0.7095 - lr: 5.0000e-07\n",
            "Epoch 247/250\n",
            "20/19 [==============================] - 17s 836ms/step - loss: 7.8676 - acc: 0.7308 - val_loss: 7.9703 - val_acc: 0.6910 - lr: 5.0000e-07\n",
            "Epoch 248/250\n",
            "20/19 [==============================] - 17s 838ms/step - loss: 7.8574 - acc: 0.7297 - val_loss: 7.9817 - val_acc: 0.6875 - lr: 5.0000e-07\n",
            "Epoch 249/250\n",
            "20/19 [==============================] - 17s 829ms/step - loss: 7.9361 - acc: 0.6844 - val_loss: 7.9847 - val_acc: 0.6956 - lr: 5.0000e-07\n",
            "Epoch 250/250\n",
            "20/19 [==============================] - 17s 827ms/step - loss: 7.9143 - acc: 0.6969 - val_loss: 7.9325 - val_acc: 0.7060 - lr: 5.0000e-07\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}