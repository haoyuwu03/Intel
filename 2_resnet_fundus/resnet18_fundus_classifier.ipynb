{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet18_fundus_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "do734Jm824Ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Tensorflow Version, Google Colab Only\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cscZ_CH23FO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8b0d77b6-88f1-4419-8e8c-d2ad635c5085"
      },
      "source": [
        "#Mount the Notebook to Drive to Access Files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpMCoOI4tclz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Imports libraries needed\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2 as cv2\n",
        "import os as os\n",
        "import h5py as h5py\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tqdm import tqdm #gives the status of a loop (important if we have large amounts of data and need to see the progress)\n",
        "\n",
        "#Tensorflow Imports\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator #used for data augmentation\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, ZeroPadding2D,\\\n",
        "     Flatten, BatchNormalization, AveragePooling2D, Dense, Activation, Add\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPui9ehjtPPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_net_block(input_data, filters, conv_size, stride):\n",
        "\n",
        "  if stride == 1:\n",
        "      shortcut = input_data\n",
        "  else:\n",
        "      shortcut = Conv2D(filters, 1, strides=(stride, stride),\n",
        "                        padding='same')(input_data)\n",
        "\n",
        "  x = Conv2D(filters, conv_size, activation=None,\n",
        "             padding='same', strides=(stride, stride))(input_data)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  x = Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Add()([shortcut, x])\n",
        "  x = Activation('relu')(x)\n",
        "  return x\n",
        "\n",
        "def resnet18():\n",
        "  num_classes = 7\n",
        "  filters = [64, 128, 256, 512]\n",
        "  activation = 'sigmoid' if num_classes == 1 else 'softmax'\n",
        "  image = Input(shape=(224,224,3), name='INPUT_LAYER')\n",
        "\n",
        "  conv1 = Conv2D(filters=64, kernel_size=(3, 3), strides=(2, 2),\n",
        "                 padding=\"same\", activation=\"relu\")(image)\n",
        "\n",
        "  max_pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv1)\n",
        "\n",
        "  res_block1 = res_net_block(max_pool1, filters[0], 3, 1)\n",
        "  res_block2 = res_net_block(res_block1, filters[0], 3, 1)\n",
        "\n",
        "  res_block3 = res_net_block(res_block2, filters[1], 3, 2)\n",
        "  res_block4 = res_net_block(res_block3, filters[1], 3, 1)\n",
        "\n",
        "  res_block5 = res_net_block(res_block4, filters[2], 3, 2)\n",
        "  res_block6 = res_net_block(res_block5, filters[2], 3, 1)\n",
        "\n",
        "  res_block7 = res_net_block(res_block6, filters[3], 3, 2)\n",
        "  res_block8 = res_net_block(res_block7, filters[3], 3, 1)\n",
        "\n",
        "  global_average = GlobalAveragePooling2D()(res_block8)\n",
        "  outputs = Dense(7, activation=activation)(global_average)\n",
        "\n",
        "  model = Model(inputs=image, outputs=outputs)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOyE7rY8w9Yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet18_model = resnet18()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICqxwjoOLHif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compiles the resnet model\n",
        "resnet18_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-3), \n",
        "                       metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLYIdEuDfD_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "503dc576-dd4b-4ba0-f60e-9b26f97b651a"
      },
      "source": [
        "resnet18_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "INPUT_LAYER (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 112, 112, 64) 1792        INPUT_LAYER[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 55, 55, 64)   36928       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 55, 55, 64)   256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 55, 55, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 55, 55, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 55, 55, 64)   256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 55, 55, 64)   0           max_pooling2d_1[0][0]            \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 55, 55, 64)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 55, 55, 64)   36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 55, 55, 64)   256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 55, 55, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 55, 55, 64)   36928       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 55, 55, 64)   256         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 55, 55, 64)   0           activation_17[0][0]              \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 55, 55, 64)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 28, 28, 128)  73856       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 28, 28, 128)  512         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 28, 28, 128)  8320        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 28, 28, 128)  512         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 28, 28, 128)  0           conv2d_25[0][0]                  \n",
            "                                                                 batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 28, 28, 128)  147584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 28, 28, 128)  512         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 128)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 28, 28, 128)  147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 28, 28, 128)  512         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 28, 28, 128)  0           activation_21[0][0]              \n",
            "                                                                 batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 28, 28, 128)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 14, 14, 256)  295168      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 14, 14, 256)  1024        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 14, 14, 256)  590080      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 14, 14, 256)  33024       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 14, 14, 256)  1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 256)  0           conv2d_30[0][0]                  \n",
            "                                                                 batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 256)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 14, 14, 256)  590080      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 14, 14, 256)  1024        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 14, 14, 256)  1024        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 256)  0           activation_25[0][0]              \n",
            "                                                                 batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 512)    1180160     activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 7, 7, 512)    2048        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 7, 7, 512)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 512)    2359808     activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 512)    131584      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 512)    2048        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 512)    0           conv2d_35[0][0]                  \n",
            "                                                                 batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 512)    0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 512)    2359808     activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 512)    2048        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 512)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 512)    2359808     activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 512)    2048        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 512)    0           activation_29[0][0]              \n",
            "                                                                 batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 512)    0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 512)          0           activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 7)            3591        global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 11,182,983\n",
            "Trainable params: 11,175,303\n",
            "Non-trainable params: 7,680\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMHlxQ452JWK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b186f24d-1690-4fed-c6fa-20c9c9fcd81d"
      },
      "source": [
        "#build the callbacks\n",
        "\n",
        "#checkpoint callback\n",
        "checkpoint_path = \"/content/gdrive/My Drive/Colab Notebooks/checkpoints/checkpoints_resnet18_fundus/training_batch_7_21_2020/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "print(checkpoint_dir)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    period=20)\n",
        "\n",
        "resnet18_model.save_weights(checkpoint_path.format(epoch=0))\n",
        "\n",
        "#learning rate decay callback\n",
        "def lrdecay(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    return lr\n",
        "\n",
        "lrdecay = tf.keras.callbacks.LearningRateScheduler(lrdecay) # learning rate decay  \n",
        "\n",
        "def earlystop(mode):\n",
        "  if mode=='acc':\n",
        "    estop = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=15, mode='max')\n",
        "  elif mode=='loss':\n",
        "    estop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, mode='min')\n",
        "  return estop\n",
        "\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/checkpoints_resnet(new)_small_fundus/training_batch_7_21_2020\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5nHpHCO2fl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loads the images from image preproccessing\n",
        "training_data = np.load('/content/gdrive/My Drive/Colab Notebooks/compressed_image_arrays/small_augmented_training_array.npy', allow_pickle=True)\n",
        "\n",
        "training_labels = np.load('/content/gdrive/My Drive/Colab Notebooks/compressed_image_arrays/small_augmented_training_labels.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v1BktwJ2kre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one hot encode the labels so that their dimensions fit the output\n",
        "def one_hot_encode(labels):\n",
        "  x = 0 #counter\n",
        "  for y in labels: #assigns a number to a label\n",
        "    if y =='cataract':\n",
        "      labels[x] = 0\n",
        "    if y == 'glaucoma':\n",
        "      labels[x] = 1\n",
        "    if y == 'diabetic_retinopathy_1':\n",
        "      labels[x] = 2\n",
        "    if y == 'diabetic_retinopathy_2':\n",
        "      labels[x] = 3\n",
        "    if y == 'diabetic_retinopathy_3':\n",
        "      labels[x] = 4\n",
        "    if y == 'diabetic_retinopathy_4':\n",
        "      labels[x] = 5\n",
        "    if y == 'normal':\n",
        "      labels[x] = 6\n",
        "    x = x+1\n",
        "  new_labels = to_categorical(labels) #one hot encodes the labels\n",
        "  return new_labels\n",
        "\n",
        "training_labels = one_hot_encode(training_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UpbGujh2mHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create ImageDataGenerator for real-time augmentation\n",
        "#We only augment the training data because we train with that data\n",
        "train_data_gen = ImageDataGenerator(zoom_range=0.3, \n",
        "                                   width_shift_range=0.2, \n",
        "                                   height_shift_range = 0.2, \n",
        "                                   rotation_range=30)\n",
        "                                   #horizontal_flip=True,\n",
        "                                   #vertical_flip=True,\n",
        "\n",
        "training_data = train_data_gen.flow(training_data, training_labels, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZImrNXn2MjA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d548596-969e-4621-e8de-cc87a9098321"
      },
      "source": [
        "batch_size = 32\n",
        "image_set_size = 1680\n",
        "resnet_train = resnet18_model.fit_generator(training_data, \n",
        "                                              epochs=160, \n",
        "                                              steps_per_epoch= image_set_size / batch_size, \n",
        "                                              callbacks=[cp_callback, lrdecay, tensorboard_callback],)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/160\n",
            "53/52 [==============================] - 19s 352ms/step - loss: 0.9300 - acc: 0.5988 - lr: 0.0010\n",
            "Epoch 2/160\n",
            "53/52 [==============================] - 18s 348ms/step - loss: 0.8794 - acc: 0.6220 - lr: 0.0010\n",
            "Epoch 3/160\n",
            "53/52 [==============================] - 19s 349ms/step - loss: 0.8480 - acc: 0.6321 - lr: 0.0010\n",
            "Epoch 4/160\n",
            "53/52 [==============================] - 18s 344ms/step - loss: 0.8785 - acc: 0.6274 - lr: 0.0010\n",
            "Epoch 5/160\n",
            "53/52 [==============================] - 18s 347ms/step - loss: 0.8679 - acc: 0.6268 - lr: 0.0010\n",
            "Epoch 6/160\n",
            "53/52 [==============================] - 18s 346ms/step - loss: 0.8205 - acc: 0.6452 - lr: 0.0010\n",
            "Epoch 7/160\n",
            "53/52 [==============================] - 18s 349ms/step - loss: 0.8452 - acc: 0.6446 - lr: 0.0010\n",
            "Epoch 8/160\n",
            "53/52 [==============================] - 18s 346ms/step - loss: 0.8111 - acc: 0.6625 - lr: 0.0010\n",
            "Epoch 9/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.7821 - acc: 0.6845 - lr: 0.0010\n",
            "Epoch 10/160\n",
            "53/52 [==============================] - ETA: 0s - loss: 0.7671 - acc: 0.6857\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints_resnet(new)_small_fundus/training_batch_7_21_2020/cp-0010.ckpt\n",
            "53/52 [==============================] - 19s 354ms/step - loss: 0.7671 - acc: 0.6857 - lr: 0.0010\n",
            "Epoch 11/160\n",
            "53/52 [==============================] - 18s 349ms/step - loss: 0.7891 - acc: 0.6643 - lr: 0.0010\n",
            "Epoch 12/160\n",
            "53/52 [==============================] - 18s 343ms/step - loss: 0.6836 - acc: 0.7220 - lr: 0.0010\n",
            "Epoch 13/160\n",
            "53/52 [==============================] - 18s 343ms/step - loss: 0.6959 - acc: 0.7101 - lr: 0.0010\n",
            "Epoch 14/160\n",
            "53/52 [==============================] - 18s 343ms/step - loss: 0.6616 - acc: 0.7345 - lr: 0.0010\n",
            "Epoch 15/160\n",
            "53/52 [==============================] - 18s 343ms/step - loss: 0.7075 - acc: 0.7196 - lr: 0.0010\n",
            "Epoch 16/160\n",
            "53/52 [==============================] - 18s 344ms/step - loss: 0.6672 - acc: 0.7179 - lr: 0.0010\n",
            "Epoch 17/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.6493 - acc: 0.7214 - lr: 0.0010\n",
            "Epoch 18/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.6842 - acc: 0.7286 - lr: 0.0010\n",
            "Epoch 19/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.6630 - acc: 0.7399 - lr: 0.0010\n",
            "Epoch 20/160\n",
            "53/52 [==============================] - 18s 340ms/step - loss: 0.6020 - acc: 0.7476 - lr: 0.0010\n",
            "Epoch 21/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.6421 - acc: 0.7458 - lr: 0.0010\n",
            "Epoch 22/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.6269 - acc: 0.7399 - lr: 0.0010\n",
            "Epoch 23/160\n",
            "53/52 [==============================] - 18s 346ms/step - loss: 0.5873 - acc: 0.7595 - lr: 0.0010\n",
            "Epoch 24/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.5603 - acc: 0.7744 - lr: 0.0010\n",
            "Epoch 25/160\n",
            "53/52 [==============================] - 18s 344ms/step - loss: 0.5735 - acc: 0.7661 - lr: 0.0010\n",
            "Epoch 26/160\n",
            "53/52 [==============================] - 18s 344ms/step - loss: 0.5759 - acc: 0.7637 - lr: 0.0010\n",
            "Epoch 27/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.5466 - acc: 0.7762 - lr: 0.0010\n",
            "Epoch 28/160\n",
            "53/52 [==============================] - 18s 344ms/step - loss: 0.5837 - acc: 0.7702 - lr: 0.0010\n",
            "Epoch 29/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.5464 - acc: 0.7899 - lr: 0.0010\n",
            "Epoch 30/160\n",
            "53/52 [==============================] - ETA: 0s - loss: 0.5409 - acc: 0.7815\n",
            "Epoch 00030: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints_resnet(new)_small_fundus/training_batch_7_21_2020/cp-0030.ckpt\n",
            "53/52 [==============================] - 18s 349ms/step - loss: 0.5409 - acc: 0.7815 - lr: 0.0010\n",
            "Epoch 31/160\n",
            "53/52 [==============================] - 18s 345ms/step - loss: 0.4692 - acc: 0.8065 - lr: 0.0010\n",
            "Epoch 32/160\n",
            "53/52 [==============================] - 18s 344ms/step - loss: 0.5243 - acc: 0.7875 - lr: 0.0010\n",
            "Epoch 33/160\n",
            "53/52 [==============================] - 18s 343ms/step - loss: 0.4863 - acc: 0.8054 - lr: 0.0010\n",
            "Epoch 34/160\n",
            "53/52 [==============================] - 18s 340ms/step - loss: 0.4471 - acc: 0.8220 - lr: 0.0010\n",
            "Epoch 35/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.4928 - acc: 0.8048 - lr: 0.0010\n",
            "Epoch 36/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.5554 - acc: 0.7821 - lr: 0.0010\n",
            "Epoch 37/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.5118 - acc: 0.7887 - lr: 0.0010\n",
            "Epoch 38/160\n",
            "53/52 [==============================] - 18s 338ms/step - loss: 0.4919 - acc: 0.7994 - lr: 0.0010\n",
            "Epoch 39/160\n",
            "53/52 [==============================] - 18s 340ms/step - loss: 0.4465 - acc: 0.8250 - lr: 0.0010\n",
            "Epoch 40/160\n",
            "53/52 [==============================] - 18s 344ms/step - loss: 0.4770 - acc: 0.8113 - lr: 0.0010\n",
            "Epoch 41/160\n",
            "53/52 [==============================] - 18s 340ms/step - loss: 0.4486 - acc: 0.8310 - lr: 0.0010\n",
            "Epoch 42/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.4377 - acc: 0.8310 - lr: 0.0010\n",
            "Epoch 43/160\n",
            "53/52 [==============================] - 18s 336ms/step - loss: 0.3978 - acc: 0.8446 - lr: 0.0010\n",
            "Epoch 44/160\n",
            "53/52 [==============================] - 18s 340ms/step - loss: 0.4387 - acc: 0.8226 - lr: 0.0010\n",
            "Epoch 45/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.4251 - acc: 0.8405 - lr: 0.0010\n",
            "Epoch 46/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.4032 - acc: 0.8488 - lr: 0.0010\n",
            "Epoch 47/160\n",
            "53/52 [==============================] - 18s 338ms/step - loss: 0.4532 - acc: 0.8262 - lr: 0.0010\n",
            "Epoch 48/160\n",
            "53/52 [==============================] - 18s 340ms/step - loss: 0.3962 - acc: 0.8476 - lr: 0.0010\n",
            "Epoch 49/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.3877 - acc: 0.8512 - lr: 0.0010\n",
            "Epoch 50/160\n",
            "53/52 [==============================] - ETA: 0s - loss: 0.3529 - acc: 0.8708\n",
            "Epoch 00050: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints_resnet(new)_small_fundus/training_batch_7_21_2020/cp-0050.ckpt\n",
            "53/52 [==============================] - 19s 350ms/step - loss: 0.3529 - acc: 0.8708 - lr: 0.0010\n",
            "Epoch 51/160\n",
            "53/52 [==============================] - 18s 345ms/step - loss: 0.3989 - acc: 0.8357 - lr: 0.0010\n",
            "Epoch 52/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.4357 - acc: 0.8304 - lr: 0.0010\n",
            "Epoch 53/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.3351 - acc: 0.8708 - lr: 0.0010\n",
            "Epoch 54/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.3464 - acc: 0.8661 - lr: 0.0010\n",
            "Epoch 55/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.3158 - acc: 0.8732 - lr: 0.0010\n",
            "Epoch 56/160\n",
            "53/52 [==============================] - 18s 338ms/step - loss: 0.3634 - acc: 0.8667 - lr: 0.0010\n",
            "Epoch 57/160\n",
            "53/52 [==============================] - 18s 345ms/step - loss: 0.3093 - acc: 0.8869 - lr: 0.0010\n",
            "Epoch 58/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.2825 - acc: 0.8893 - lr: 0.0010\n",
            "Epoch 59/160\n",
            "53/52 [==============================] - 18s 343ms/step - loss: 0.2884 - acc: 0.8863 - lr: 0.0010\n",
            "Epoch 60/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.3434 - acc: 0.8690 - lr: 0.0010\n",
            "Epoch 61/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.2715 - acc: 0.9006 - lr: 0.0010\n",
            "Epoch 62/160\n",
            "53/52 [==============================] - 18s 338ms/step - loss: 0.3426 - acc: 0.8702 - lr: 0.0010\n",
            "Epoch 63/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.2518 - acc: 0.9095 - lr: 0.0010\n",
            "Epoch 64/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.2764 - acc: 0.8952 - lr: 0.0010\n",
            "Epoch 65/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.2433 - acc: 0.9137 - lr: 0.0010\n",
            "Epoch 66/160\n",
            "53/52 [==============================] - 18s 343ms/step - loss: 0.2548 - acc: 0.9083 - lr: 0.0010\n",
            "Epoch 67/160\n",
            "53/52 [==============================] - 18s 340ms/step - loss: 0.2799 - acc: 0.8946 - lr: 0.0010\n",
            "Epoch 68/160\n",
            "53/52 [==============================] - 18s 338ms/step - loss: 0.2296 - acc: 0.9196 - lr: 0.0010\n",
            "Epoch 69/160\n",
            "53/52 [==============================] - 18s 338ms/step - loss: 0.2945 - acc: 0.8940 - lr: 0.0010\n",
            "Epoch 70/160\n",
            "53/52 [==============================] - ETA: 0s - loss: 0.2599 - acc: 0.9000\n",
            "Epoch 00070: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints_resnet(new)_small_fundus/training_batch_7_21_2020/cp-0070.ckpt\n",
            "53/52 [==============================] - 18s 349ms/step - loss: 0.2599 - acc: 0.9000 - lr: 0.0010\n",
            "Epoch 71/160\n",
            "53/52 [==============================] - 18s 346ms/step - loss: 0.2546 - acc: 0.9077 - lr: 0.0010\n",
            "Epoch 72/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.2627 - acc: 0.8976 - lr: 0.0010\n",
            "Epoch 73/160\n",
            "53/52 [==============================] - 18s 340ms/step - loss: 0.2398 - acc: 0.9119 - lr: 0.0010\n",
            "Epoch 74/160\n",
            "53/52 [==============================] - 18s 345ms/step - loss: 0.2210 - acc: 0.9137 - lr: 0.0010\n",
            "Epoch 75/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.1922 - acc: 0.9250 - lr: 0.0010\n",
            "Epoch 76/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.2048 - acc: 0.9268 - lr: 0.0010\n",
            "Epoch 77/160\n",
            "53/52 [==============================] - 18s 340ms/step - loss: 0.1818 - acc: 0.9351 - lr: 0.0010\n",
            "Epoch 78/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.2039 - acc: 0.9268 - lr: 0.0010\n",
            "Epoch 79/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.2192 - acc: 0.9113 - lr: 0.0010\n",
            "Epoch 80/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.1716 - acc: 0.9411 - lr: 0.0010\n",
            "Epoch 81/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.2034 - acc: 0.9244 - lr: 0.0010\n",
            "Epoch 82/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.1559 - acc: 0.9482 - lr: 1.0000e-04\n",
            "Epoch 83/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.0950 - acc: 0.9708 - lr: 1.0000e-04\n",
            "Epoch 84/160\n",
            "53/52 [==============================] - 18s 344ms/step - loss: 0.0875 - acc: 0.9696 - lr: 1.0000e-04\n",
            "Epoch 85/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.0933 - acc: 0.9708 - lr: 1.0000e-04\n",
            "Epoch 86/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.0866 - acc: 0.9732 - lr: 1.0000e-04\n",
            "Epoch 87/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.0795 - acc: 0.9726 - lr: 1.0000e-04\n",
            "Epoch 88/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.0862 - acc: 0.9762 - lr: 1.0000e-04\n",
            "Epoch 89/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.0808 - acc: 0.9786 - lr: 1.0000e-04\n",
            "Epoch 90/160\n",
            "53/52 [==============================] - ETA: 0s - loss: 0.0736 - acc: 0.9768\n",
            "Epoch 00090: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints_resnet(new)_small_fundus/training_batch_7_21_2020/cp-0090.ckpt\n",
            "53/52 [==============================] - 19s 357ms/step - loss: 0.0736 - acc: 0.9768 - lr: 1.0000e-04\n",
            "Epoch 91/160\n",
            "53/52 [==============================] - 19s 352ms/step - loss: 0.0692 - acc: 0.9774 - lr: 1.0000e-04\n",
            "Epoch 92/160\n",
            "53/52 [==============================] - 18s 343ms/step - loss: 0.0765 - acc: 0.9792 - lr: 1.0000e-04\n",
            "Epoch 93/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.0716 - acc: 0.9768 - lr: 1.0000e-04\n",
            "Epoch 94/160\n",
            "53/52 [==============================] - 18s 343ms/step - loss: 0.0755 - acc: 0.9756 - lr: 1.0000e-04\n",
            "Epoch 95/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.0754 - acc: 0.9768 - lr: 1.0000e-04\n",
            "Epoch 96/160\n",
            "53/52 [==============================] - 18s 343ms/step - loss: 0.0642 - acc: 0.9786 - lr: 1.0000e-04\n",
            "Epoch 97/160\n",
            "53/52 [==============================] - 18s 340ms/step - loss: 0.0535 - acc: 0.9851 - lr: 1.0000e-04\n",
            "Epoch 98/160\n",
            "53/52 [==============================] - 18s 340ms/step - loss: 0.0689 - acc: 0.9786 - lr: 1.0000e-04\n",
            "Epoch 99/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.0517 - acc: 0.9851 - lr: 1.0000e-04\n",
            "Epoch 100/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.0503 - acc: 0.9839 - lr: 1.0000e-04\n",
            "Epoch 101/160\n",
            "53/52 [==============================] - 18s 342ms/step - loss: 0.0640 - acc: 0.9774 - lr: 1.0000e-04\n",
            "Epoch 102/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.0411 - acc: 0.9881 - lr: 1.0000e-04\n",
            "Epoch 103/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.0459 - acc: 0.9863 - lr: 1.0000e-04\n",
            "Epoch 104/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.0714 - acc: 0.9821 - lr: 1.0000e-04\n",
            "Epoch 105/160\n",
            "53/52 [==============================] - 18s 340ms/step - loss: 0.0521 - acc: 0.9875 - lr: 1.0000e-04\n",
            "Epoch 106/160\n",
            "53/52 [==============================] - 18s 338ms/step - loss: 0.0479 - acc: 0.9857 - lr: 1.0000e-04\n",
            "Epoch 107/160\n",
            "53/52 [==============================] - 18s 344ms/step - loss: 0.0557 - acc: 0.9810 - lr: 1.0000e-04\n",
            "Epoch 108/160\n",
            "53/52 [==============================] - 18s 347ms/step - loss: 0.0552 - acc: 0.9839 - lr: 1.0000e-04\n",
            "Epoch 109/160\n",
            "53/52 [==============================] - 18s 339ms/step - loss: 0.0425 - acc: 0.9893 - lr: 1.0000e-04\n",
            "Epoch 110/160\n",
            "53/52 [==============================] - ETA: 0s - loss: 0.0595 - acc: 0.9833\n",
            "Epoch 00110: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints_resnet(new)_small_fundus/training_batch_7_21_2020/cp-0110.ckpt\n",
            "53/52 [==============================] - 19s 352ms/step - loss: 0.0595 - acc: 0.9833 - lr: 1.0000e-04\n",
            "Epoch 111/160\n",
            "53/52 [==============================] - 18s 345ms/step - loss: 0.0559 - acc: 0.9798 - lr: 1.0000e-04\n",
            "Epoch 112/160\n",
            "53/52 [==============================] - 18s 343ms/step - loss: 0.0604 - acc: 0.9827 - lr: 1.0000e-04\n",
            "Epoch 113/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.0543 - acc: 0.9827 - lr: 1.0000e-04\n",
            "Epoch 114/160\n",
            "53/52 [==============================] - 18s 341ms/step - loss: 0.0733 - acc: 0.9804 - lr: 1.0000e-04\n",
            "Epoch 115/160\n",
            "53/52 [==============================] - 18s 340ms/step - loss: 0.0433 - acc: 0.9881 - lr: 1.0000e-04\n",
            "Epoch 116/160\n",
            "53/52 [==============================] - 18s 340ms/step - loss: 0.0432 - acc: 0.9863 - lr: 1.0000e-04\n",
            "Epoch 117/160\n",
            "53/52 [==============================] - 18s 344ms/step - loss: 0.0420 - acc: 0.9869 - lr: 1.0000e-04\n",
            "Epoch 118/160\n",
            "53/52 [==============================] - 19s 354ms/step - loss: 0.0338 - acc: 0.9905 - lr: 1.0000e-04\n",
            "Epoch 119/160\n",
            "53/52 [==============================] - 19s 360ms/step - loss: 0.0372 - acc: 0.9875 - lr: 1.0000e-04\n",
            "Epoch 120/160\n",
            "53/52 [==============================] - 19s 354ms/step - loss: 0.0406 - acc: 0.9887 - lr: 1.0000e-04\n",
            "Epoch 121/160\n",
            "53/52 [==============================] - 19s 354ms/step - loss: 0.0499 - acc: 0.9833 - lr: 1.0000e-04\n",
            "Epoch 122/160\n",
            "53/52 [==============================] - 19s 351ms/step - loss: 0.0447 - acc: 0.9851 - lr: 1.0000e-05\n",
            "Epoch 123/160\n",
            "53/52 [==============================] - 19s 352ms/step - loss: 0.0425 - acc: 0.9893 - lr: 1.0000e-05\n",
            "Epoch 124/160\n",
            "53/52 [==============================] - 19s 357ms/step - loss: 0.0343 - acc: 0.9899 - lr: 1.0000e-05\n",
            "Epoch 125/160\n",
            "53/52 [==============================] - 19s 354ms/step - loss: 0.0451 - acc: 0.9863 - lr: 1.0000e-05\n",
            "Epoch 126/160\n",
            "53/52 [==============================] - 19s 354ms/step - loss: 0.0395 - acc: 0.9875 - lr: 1.0000e-05\n",
            "Epoch 127/160\n",
            "53/52 [==============================] - 19s 355ms/step - loss: 0.0366 - acc: 0.9887 - lr: 1.0000e-05\n",
            "Epoch 128/160\n",
            "53/52 [==============================] - 19s 354ms/step - loss: 0.0381 - acc: 0.9893 - lr: 1.0000e-05\n",
            "Epoch 129/160\n",
            "53/52 [==============================] - 19s 356ms/step - loss: 0.0370 - acc: 0.9905 - lr: 1.0000e-05\n",
            "Epoch 130/160\n",
            "53/52 [==============================] - ETA: 0s - loss: 0.0338 - acc: 0.9899\n",
            "Epoch 00130: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints_resnet(new)_small_fundus/training_batch_7_21_2020/cp-0130.ckpt\n",
            "53/52 [==============================] - 19s 366ms/step - loss: 0.0338 - acc: 0.9899 - lr: 1.0000e-05\n",
            "Epoch 131/160\n",
            "53/52 [==============================] - 19s 362ms/step - loss: 0.0432 - acc: 0.9851 - lr: 1.0000e-05\n",
            "Epoch 132/160\n",
            "53/52 [==============================] - 19s 355ms/step - loss: 0.0413 - acc: 0.9869 - lr: 1.0000e-05\n",
            "Epoch 133/160\n",
            "53/52 [==============================] - 19s 357ms/step - loss: 0.0469 - acc: 0.9851 - lr: 1.0000e-05\n",
            "Epoch 134/160\n",
            "53/52 [==============================] - 19s 359ms/step - loss: 0.0381 - acc: 0.9887 - lr: 1.0000e-05\n",
            "Epoch 135/160\n",
            "53/52 [==============================] - 19s 357ms/step - loss: 0.0418 - acc: 0.9845 - lr: 1.0000e-05\n",
            "Epoch 136/160\n",
            "53/52 [==============================] - 19s 358ms/step - loss: 0.0320 - acc: 0.9917 - lr: 1.0000e-05\n",
            "Epoch 137/160\n",
            "53/52 [==============================] - 19s 356ms/step - loss: 0.0457 - acc: 0.9857 - lr: 1.0000e-05\n",
            "Epoch 138/160\n",
            "53/52 [==============================] - 19s 358ms/step - loss: 0.0267 - acc: 0.9935 - lr: 1.0000e-05\n",
            "Epoch 139/160\n",
            "53/52 [==============================] - 19s 358ms/step - loss: 0.0310 - acc: 0.9911 - lr: 1.0000e-05\n",
            "Epoch 140/160\n",
            "53/52 [==============================] - 19s 363ms/step - loss: 0.0296 - acc: 0.9929 - lr: 1.0000e-05\n",
            "Epoch 141/160\n",
            "53/52 [==============================] - 19s 358ms/step - loss: 0.0417 - acc: 0.9875 - lr: 1.0000e-05\n",
            "Epoch 142/160\n",
            "53/52 [==============================] - 19s 354ms/step - loss: 0.0299 - acc: 0.9946 - lr: 1.0000e-05\n",
            "Epoch 143/160\n",
            "53/52 [==============================] - 19s 356ms/step - loss: 0.0345 - acc: 0.9875 - lr: 1.0000e-05\n",
            "Epoch 144/160\n",
            "53/52 [==============================] - 19s 357ms/step - loss: 0.0425 - acc: 0.9887 - lr: 1.0000e-05\n",
            "Epoch 145/160\n",
            "53/52 [==============================] - 19s 358ms/step - loss: 0.0371 - acc: 0.9887 - lr: 1.0000e-05\n",
            "Epoch 146/160\n",
            "53/52 [==============================] - 19s 357ms/step - loss: 0.0231 - acc: 0.9923 - lr: 1.0000e-05\n",
            "Epoch 147/160\n",
            "53/52 [==============================] - 19s 356ms/step - loss: 0.0246 - acc: 0.9935 - lr: 1.0000e-05\n",
            "Epoch 148/160\n",
            "53/52 [==============================] - 19s 357ms/step - loss: 0.0438 - acc: 0.9833 - lr: 1.0000e-05\n",
            "Epoch 149/160\n",
            "53/52 [==============================] - 19s 358ms/step - loss: 0.0261 - acc: 0.9935 - lr: 1.0000e-05\n",
            "Epoch 150/160\n",
            "53/52 [==============================] - ETA: 0s - loss: 0.0373 - acc: 0.9845\n",
            "Epoch 00150: saving model to /content/gdrive/My Drive/Colab Notebooks/checkpoints_resnet(new)_small_fundus/training_batch_7_21_2020/cp-0150.ckpt\n",
            "53/52 [==============================] - 19s 366ms/step - loss: 0.0373 - acc: 0.9845 - lr: 1.0000e-05\n",
            "Epoch 151/160\n",
            "53/52 [==============================] - 19s 365ms/step - loss: 0.0415 - acc: 0.9881 - lr: 1.0000e-05\n",
            "Epoch 152/160\n",
            "53/52 [==============================] - 19s 360ms/step - loss: 0.0348 - acc: 0.9887 - lr: 1.0000e-05\n",
            "Epoch 153/160\n",
            "53/52 [==============================] - 19s 357ms/step - loss: 0.0371 - acc: 0.9881 - lr: 1.0000e-05\n",
            "Epoch 154/160\n",
            "53/52 [==============================] - 19s 358ms/step - loss: 0.0358 - acc: 0.9905 - lr: 1.0000e-05\n",
            "Epoch 155/160\n",
            "53/52 [==============================] - 19s 359ms/step - loss: 0.0360 - acc: 0.9899 - lr: 1.0000e-05\n",
            "Epoch 156/160\n",
            "53/52 [==============================] - 19s 362ms/step - loss: 0.0301 - acc: 0.9935 - lr: 1.0000e-05\n",
            "Epoch 157/160\n",
            "53/52 [==============================] - 19s 358ms/step - loss: 0.0271 - acc: 0.9935 - lr: 1.0000e-05\n",
            "Epoch 158/160\n",
            "53/52 [==============================] - 19s 359ms/step - loss: 0.0364 - acc: 0.9905 - lr: 1.0000e-05\n",
            "Epoch 159/160\n",
            "53/52 [==============================] - 19s 363ms/step - loss: 0.0418 - acc: 0.9887 - lr: 1.0000e-05\n",
            "Epoch 160/160\n",
            "53/52 [==============================] - 19s 358ms/step - loss: 0.0315 - acc: 0.9929 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJOKn29ixkCA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a20dd802-2d78-463e-a28e-b63b2e6a80f0"
      },
      "source": [
        "resnet18_model.save('/content/gdrive/My Drive/Colab Notebooks/resnet18_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/Colab Notebooks/resnet18_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}